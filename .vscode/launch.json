{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "AutoTestIA (PPTX Input)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py", // Assumes main.py is in the workspace root
            "args": [
                "C:/Users/Oscar/My Drive (oscarj1994@gmail.com)/9. DOCENCIA/2024-2025/2nd sem - Procesamiento del Lenguaje Natural/Tema 5b.pptx",
                "-n", "4", //"2",
                "--provider", "anthropic",
                "--generator-model", "claude-sonnet-4-5", //"gpt-4o-mini",
                "--reviewer-model", "claude-sonnet-4-5", //"gpt-4o-mini",
                "--use-llm-review",
                "-f", "none", //"gift", "wooclap", "rexams"
                "-o", "generated/tema5b_new.md",
                "--generator-instructions", "Create questions about the specifics of LDA, LSA / LSI",
                // "--log-level", "DEBUG",
            ],
            "console": "integratedTerminal", // Run in VS Code's integrated terminal
            "justMyCode": true // Debug only user code by default
        },
        {
            "name": "AutoTestIA (MD Input)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py", // Assumes main.py is in the workspace root
            "args": [
                "C:/Users/Oscar/pptx2marp/outputs/Tema_5c_marp.md",
                "-n", "10", //"2",
                "--provider", "anthropic",
                "--generator-model", "claude-sonnet-4-5", //"gpt-4o-mini",
                "--reviewer-model", "claude-sonnet-4-5", //"gpt-4o-mini",
                "--use-llm-review",
                "-f", "none", //"gift", "wooclap", "rexams"
                "-o", "generated/tema5c_marp.md",
                //"--generator-instructions", "Create questions about the specifics of LDA, LSA / LSI",
                // "--log-level", "DEBUG",
            ],
            "console": "integratedTerminal", // Run in VS Code's integrated terminal
            "justMyCode": true // Debug only user code by default
        },
        {
            "name": "Generate Regex (Instructions)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                // No positional input file argument
                "-n", "6",
                "-o", "generated/python_regex_questions_2.md",
                "--provider", "anthropic", // Or change to your preferred provider
                "--generator-instructions", "Generate multiple-choice questions specifically about Python regular expressions using the 're' module. Focus on questions requiring either synthesis (writing a regex pattern based on a description) or analysis (determining what a given regex pattern matches or does). Cover common concepts like character classes, quantifiers, grouping, anchors, lookarounds, and standard 're' functions (e.g., search, match, findall, sub).",
                "--use-llm-review",
                "--reviewer-instructions", "Ensure questions accurately test Python regex synthesis or analysis as requested. Verify the correctness of regex patterns, expected matches, and explanations. Ensure distractors are plausible but incorrect applications or interpretations of regex concepts.",
                "--exam-language", "Spanish",
                "-f", "none", //"moodle_xml", "gift", "wooclap", "rexams", "none"
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Resume from .md to Wooclap",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                "--resume-from-md", "generated/all_subset.md", // Resume from this file
                "-f", "wooclap", // Output Wooclap format
                "--shuffle-questions", "123",
                "--shuffle-answers", "123",
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Resume from .md to R/Exams",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                "--resume-from-md", "generated/mib/splits/all_2_evaluated-final.md", // Resume from this file
                "-f", "rexams", // Output R/Exams format
                "--rexams-title", "Sistemas informáticos y sistemas de información - Examen Parcial",
                "--rexams-course", "Máster en Ingeniería Biomédica",
                // "--shuffle-questions", "123",
                "--shuffle-answers", "123",
                // "--log-level", "DEBUG",
                "--rexams-date", "2025-10-22", 
                // "--evaluate-final",
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Split Questions Script",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/autotestia/output_formatter/split_markdown.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "cwd": "${workspaceFolder}", // Run from project root
            "args": [
                "generated/mib/all.md", // Input MD file
                "--splits", "20", "35", "-1", // Split proportions
                "--output-dir", "generated/mib/splits", // Output directory
                "--shuffle-questions", "123" // Shuffle seed
            ]
        },
        {
            "name": "Correct R/Exams from PDF",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/autotestia/rexams/correct_exams.py",
            "args": [
                "--all-scans-pdf", "./generated/mib/splits/all_2_evaluated-final_rexams_pdf_output/20251022182231907.pdf",
                "--student-info-csv", "generated/mib/splits/all_2_evaluated-final.csv",
                "--solutions-rds", "generated/mib/splits/all_2_evaluated-final_rexams_pdf_output/exam.rds",
                "--output-path", "generated/mib/splits/all_2_evaluated-final_rexams_corrected",
                "--exam-language", "es",
                "--partial-eval",
                "--negative-points", "-0.333333",
                "--scale-mark-to", "10.0",
                "--student-csv-id-col", "Número ID",
                "--student-csv-reg-col", "DNI",
                "--student-csv-name-col", "Nom",
                "--student-csv-surname-col", "Cognoms",
                "--student-csv-encoding", "UTF-8",
                "--registration-format", "%08s",
                "--python-rotate",
                "--python-split",
                "--max-score", "32",
                "--log-level", "INFO",
                // "--force-overwrite",
                // "--python-bw-threshold", "170",
                // "--void-questions-nicely", "14",
            ],
            "console": "integratedTerminal",
            "justMyCode": true,
            "cwd": "${workspaceFolder}"
        },
    {
        "name": "Correct R/Exams (Manual CSV)",
        "type": "debugpy",
        "request": "launch",
        "program": "${workspaceFolder}/autotestia/rexams/correct_exams_manual.py",
        "args": [
            "--corrected-answers-csv", "generated/splits/pln_2025_gem.csv",
            "--solutions-rds", "generated/splits/final_rexams_pdf_output/exam.rds",
            "--output-path", "generated/splits/final_manual_corrected",
            "--partial-eval",
            "--negative-points", "-0.333333",
            "--max-score", "30",
            "--scale-mark-to", "10.0"
        ],
        "console": "integratedTerminal",
        "justMyCode": true,
        "cwd": "${workspaceFolder}"
        },
        // Exams from MIB
        {
            "name": "AutoTestIA (MD Input - MIB)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py", // Assumes main.py is in the workspace root
            "args": [
                "C:\\Users\\Oscar\\My Drive (oscarj1994@gmail.com)\\9. DOCENCIA\\2025-2026\\1er sem - MIB - Sistemas informáticos y sistemas de información\\slides_2025\\xml.md",
                "-n", "20",
                // "--provider", "ollama",
                // "--provider", "openrouter",
                "--generator-model", "google/gemini-2.5-pro",
                "--reviewer-model", "google/gemini-2.5-flash", 
                "--evaluator-model", "google/gemini-2.5-flash",
                "--use-llm-review",
                "-f", "none", //"gift", "wooclap", "rexams"
                "-o", "generated/mib/xml_gemini25proflash.md",
                "--exam-language", "es",
                "--generator-instructions", "Include some exercises, both for synthesis and analysis",
                // "--generator-instructions", "Use the material only until the Azure section, as we did not cover Azure in class",
                // "--generator-instructions", "Include some exercises about subnetting and number system conversions",
                // "--log-level", "DEBUG",
                "--evaluate-initial",
                "--evaluate-reviewed",
            ],
            "console": "integratedTerminal", // Run in VS Code's integrated terminal
            "justMyCode": true // Debug only user code by default
        },
        {
            "name": "Resume from .md to pexams",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                "--resume-from-md", "generated/mib/splits/all_2_evaluated-final.md", // Resume from this file
                "-f", "pexams", // Output pexams format
                "--exam-title", "Sistemas informáticos y sistemas de información - Examen Parcial",
                "--exam-course", "Máster en Ingeniería Biomédica",
                // "--shuffle-questions", "123",
                "--shuffle-answers", "123",
                "--exam-date", "2025-10-22", 
                "--exam-models", "1",
                // "--evaluate-final",
                "--exam-font-size", "10pt",
                "--exam-language", "es",
                "--exam-generate-fakes", "1",
                "--exam-generate-references",
                "--log-level", "DEBUG",
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Pexams: Correct Simulated Scans",
            "type": "python",
            "request": "launch",
            "module": "autotestia.correct_pexams",
            "cwd": "${workspaceFolder}",
            "args": [
                "--input-path",
                "generated/mib/splits/all_2_evaluated-final_pexams_output/simulated_scans",
                "--exam-dir",
                "generated/mib/splits/all_2_evaluated-final_pexams_output",
                "--output-dir",
                "generated/mib/splits/all_2_evaluated-final_pexams_output/correction_results",
                "--log-level", "DEBUG"
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        }
    ]
} 