{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "AutoTestIA (PPTX Input)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py", // Assumes main.py is in the workspace root
            "args": [
                "C:/Users/Oscar/My Drive (oscarj1994@gmail.com)/9. DOCENCIA/2024-2025/2nd sem - Procesamiento del Lenguaje Natural/Tema 5b.pptx",
                "-n", "4", //"2",
                "--provider", "anthropic",
                "--generator-model", "claude-3-7-sonnet-latest", //"gpt-4o-mini",
                "--reviewer-model", "claude-3-7-sonnet-latest", //"gpt-4o-mini",
                "--use-llm-review",
                "-f", "none", //"gift", "wooclap", "rexams"
                "-o", "generated/tema5b_new.md",
                "--generator-instructions", "Create questions about the specifics of LDA, LSA / LSI",
                // "--log-level", "DEBUG",
            ],
            "console": "integratedTerminal", // Run in VS Code's integrated terminal
            "justMyCode": true // Debug only user code by default
        },
        {
            "name": "AutoTestIA (MD Input)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py", // Assumes main.py is in the workspace root
            "args": [
                "C:/Users/Oscar/pptx2marp/outputs/Tema_5c_marp.md",
                "-n", "10", //"2",
                "--provider", "anthropic",
                "--generator-model", "claude-3-7-sonnet-latest", //"gpt-4o-mini",
                "--reviewer-model", "claude-3-7-sonnet-latest", //"gpt-4o-mini",
                "--use-llm-review",
                "-f", "none", //"gift", "wooclap", "rexams"
                "-o", "generated/tema5c_marp.md",
                //"--generator-instructions", "Create questions about the specifics of LDA, LSA / LSI",
                // "--log-level", "DEBUG",
            ],
            "console": "integratedTerminal", // Run in VS Code's integrated terminal
            "justMyCode": true // Debug only user code by default
        },
        {
            "name": "Generate Regex (Instructions)",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                // No positional input file argument
                "-n", "6",
                "-o", "generated/python_regex_questions_2.md",
                "--provider", "anthropic", // Or change to your preferred provider
                "--generator-instructions", "Generate multiple-choice questions specifically about Python regular expressions using the 're' module. Focus on questions requiring either synthesis (writing a regex pattern based on a description) or analysis (determining what a given regex pattern matches or does). Cover common concepts like character classes, quantifiers, grouping, anchors, lookarounds, and standard 're' functions (e.g., search, match, findall, sub).",
                "--use-llm-review",
                "--reviewer-instructions", "Ensure questions accurately test Python regex synthesis or analysis as requested. Verify the correctness of regex patterns, expected matches, and explanations. Ensure distractors are plausible but incorrect applications or interpretations of regex concepts.",
                "--language", "Spanish",
                "-f", "none", //"moodle_xml", "gift", "wooclap", "rexams", "none"
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Resume from .md to Wooclap",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                "--resume-from-md", "generated/all_subset.md", // Resume from this file
                "-f", "wooclap", // Output Wooclap format
                "--shuffle-questions", "123",
                "--shuffle-answers", "123",
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Resume from .md to R/Exams",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "args": [
                "--resume-from-md", "generated/splits/recuperacion_final.md", // Resume from this file
                "-f", "rexams", // Output R/Exams format
                "--rexams-title", "Procesado del Lenguaje Natural - Examen Final", //Procesado del Lenguaje Natural - Examen Recuperación
                "--rexams-course", "Grado en Ciencia de Datos",
                // "--shuffle-questions", "123",
                "--shuffle-answers", "123",
                "--log-level", "DEBUG",
                "--rexams-date", "2025-06-05" //Fecha de recuperación: 25/06/2025
            ],
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Split Questions Script",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/output_formatter/split_markdown.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "cwd": "${workspaceFolder}", // Run from project root
            "args": [
                "generated/all.md", // Input MD file
                "--splits", "0.5", "0.5", // Split proportions
                "--output-dir", "generated/splits", // Output directory
                "--shuffle-questions", "123" // Shuffle seed
            ]
        },
        {
            "name": "Correct R/Exams from PDF",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/autotestia/rexams/correct_exams.py",
            "args": [
                "--all-scans-pdf", "generated/splits/recuperacion_rexams_corrected/20250605165231892.pdf",
                "--student-info-csv", "generated/splits/pln_2025.csv",
                "--solutions-rds", "generated/splits/recuperacion_rexams_pdf_output/exam.rds",
                "--output-path", "generated/splits/recuperacion_rexams_corrected",
                "--language", "es",
                "--partial-eval",
                "--negative-points", "-0.333333",
                "--scale-mark-to", "10.0",
                "--student-csv-id-col", "Número ID",
                "--student-csv-reg-col", "DNI",
                "--student-csv-name-col", "Nom",
                "--student-csv-surname-col", "Cognoms",
                "--student-csv-encoding", "UTF-8",
                "--registration-format", "%08s",
                "--python-rotate",
                "--python-split",
                "--max-score", "30",
                "--log-level", "INFO",
                "--force-overwrite",
                "--python-bw-threshold", "170",
                // "--void-questions-nicely", "14",
            ],
            "console": "integratedTerminal",
            "justMyCode": true,
            "cwd": "${workspaceFolder}"
        },
    {
        "name": "Correct R/Exams (Manual CSV)",
        "type": "debugpy",
        "request": "launch",
        "program": "${workspaceFolder}/autotestia/rexams/correct_exams_manual.py",
        "args": [
            "--corrected-answers-csv", "generated/splits/pln_2025_gem.csv",
            "--solutions-rds", "generated/splits/final_rexams_pdf_output/exam.rds",
            "--output-path", "generated/splits/final_manual_corrected",
            "--partial-eval",
            "--negative-points", "-0.333333",
            "--max-score", "30",
            "--scale-mark-to", "10.0"
        ],
        "console": "integratedTerminal",
        "justMyCode": true,
        "cwd": "${workspaceFolder}"
        }
    ]
} 